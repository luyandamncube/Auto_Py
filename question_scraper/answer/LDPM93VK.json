{"question": "You have an Azure data solution that contains an Azure SQL data warehouse named DW1.Several users execute adhoc queries to DW1 concurrently.You regularly perform automated data loads to DW1.You need to ensure that the automated data loads have enough memory available to complete quickly and successfully when the adhoc queries runWhat should you do?\nA.Hash distribute the large fact tables in DW1 before performing the automated data loads.\nB.Assign a larger resource class to the automated data load queries.\nC.Create sampled statistics for every column in each table of DW1.\nD.Assign a smaller resource class to the automated data load queries.", "answer": "B", "description": "To ensure the loading user has enough memory to achieve maximum compression rates, use loading users that are a member of a medium or large resourceclass.References:https://docs.microsoft.com/en-us/azure/sql-data-warehouse/guidance-for-loading-data"}