{"question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that mightmeet the stated goals. Some questions sets might have more than one correct solution, while others might not have a correct solution.After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.You need setup monitoring for tiers 6 through 8.What should you configure?\nA.extended events for average storage percentage that emails data engineers\nB.an alert rule to monitor CPU percentage in databases that emails data engineers\nC.an alert rule to monitor CPU percentage in elastic pools that emails data engineers\nD.an alert rule to monitor storage percentage in databases that emails data engineers\nE.an alert rule to monitor storage percentage in elastic pools that emails data engineers", "answer": "E", "description": "Scenario:Tiers 6 through 8 must have unexpected resource storage usage immediately reported to data engineers.Tier 3 and Tier 6 through Tier 8 applications must use database density on the same server and Elastic pools in a cost-effective manner.Testlet 3Case StudyThis is a case study. Case studies are not timed separately. You can use as much exam time as you would like to complete each case. However, there maybe additional case studies and sections on this exam. You must manage your time to ensure that you are able to complete all questions included on this exam inthe time provided.To answer the questions included in a case study, you will need to reference information that is provided in the case study. Case studies might contain exhibits andother resources that provide more information about the scenario that is described in the case study. Each question is independent of the other question on thiscase study.At the end of this case study, a review screen will appear. This screen allows you to review your answers and to make changes before you move to the next sectionof the exam. After you begin a new section, you cannot return to this section.To start the case studyTo display the first question on this case study, click the Next button. Use the buttons in the left pane to explore the content of the case study before you answer thequestions. Clicking these buttons displays information such as business requirements, existing environment, and problem statements. If the case study has an AllInformation tab, note that the information displayed is identical to the information displayed on the subsequent tabs. When you are ready to answer a question,click the Question button to return to the question.OverviewGeneral OverviewLitware, Inc, is an international car racing and manufacturing company that has 1,000 employees. Most employees are located in Europe. The company supportsracing teams that complete in a worldwide racing series.Physical LocationsLitware has two main locations: a main office in London, England, and a manufacturing plant in Berlin, Germany.During each race weekend, 100 engineers set up a remote portable office by using a VPN to connect the datacentre in the London office. The portable office is setup and torn down in approximately 20 different countries each year.Existing environmentRace CentralDuring race weekends, Litware uses a primary application named Race Central. Each car has several sensors that send real-time telemetry data to the Londondatacentre. The data is used for real-time tracking of the cars.Race Central also sends batch updates to an application named Mechanical Workflow by using Microsoft SQL Server Integration Services (SSIS).The telemetry data is sent to a MongoDB database. A custom application then moves the data to databases in SQL Server 2017. The telemetry data in MongoDBhas more than 500 attributes. The application changes the attribute names when the data is moved to SQL Server 2017.The database structure contains both OLAP and OLTP databases.Mechanical WorkflowMechanical Workflow is used to track changes and improvements made to the cars during their lifetime.Currently, Mechanical Workflow runs on SQL Server 2017 as an OLAP system.Mechanical Workflow has a named Table1 that is 1 TB. Large aggregations are performed on a single column of Table 1.RequirementsPlanned ChangesLitware is the process of rearchitecting its data estate to be hosted in Azure. The company plans to decommission the London datacentre and move all itsapplications to an Azure datacentre.Technical RequirementsLitware identifies the following technical requirements:Data collection for Race Central must be moved to Azure Cosmos DB and Azure SQL Database. The data must be written to the Azure datacentre closest toeach race and must converge in the least amount of time.The query performance of Race Central must be stable, and the administrative time it takes to perform optimizations must be minimized.The datacentre for Mechanical Workflow must be moved to Azure SQL data Warehouse.Transparent data encryption (IDE) must be enabled on all data stores, whenever possible.An Azure Data Factory pipeline must be used to move data from Cosmos DB to SQL Database for Race Central. If the data load takes longer than 20 minutes,configuration changes must be made to Data Factory.The telemetry data must migrate toward a solution that is native to Azure.The telemetry data must be monitored for performance issues. You must adjust the Cosmos DB Request Units per second (RU/s) to maintain a performanceSLA while minimizing the cost of the Ru/s.Data Masking RequirementsDuring rare weekends, visitors will be able to enter the remote portable offices. Litware is concerned that some proprietary information might be exposed. Thecompany identifies the following data masking requirements for the Race Central data that will be stored in SQL Database:Only show the last four digits of the values in a column named SuspensionSprings.Only Show a zero value for the values in a column named ShockOilWeight."}