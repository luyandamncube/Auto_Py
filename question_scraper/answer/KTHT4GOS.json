{"question": "You need to develop a pipeline for processing data. The pipeline must meet the following requirements:Scale up and down resources for cost reductionUse an in-memory data processing engine to speed up ETL and machine learning operations.Use streaming capabilitiesProvide the ability to code in SQL, Python, Scala, and RIntegrate workspace collaboration with Git   What should you use?\nA.HDInsight Spark Cluster\nB.Azure Stream Analytics\nC.HDInsight Hadoop Cluster\nD.Azure SQL Data Warehouse\nE.HDInsight Kafka Cluster\nF.HDInsight Storm Cluster", "answer": "A", "description": "Aparch Spark is an open-source, parallel-processing framework that supports in-memory processing to boost the performance of big-data analysis applications.HDInsight is a managed Hadoop service. Use it deploy and manage Hadoop clusters in Azure. For batch processing, you can use Spark, Hive, Hive LLAP,MapReduce.Languages: R, Python, Java, Scala, SQLYou can create an HDInsight Spark cluster using an Azure Resource Manager template. The template can be found in GitHub.References: https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/batch-processing"}